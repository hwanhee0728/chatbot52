__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

import os
os.environ["PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION"] = "python"

import streamlit as st

from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.callbacks.base import BaseCallbackHandler
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
#load_dotenv()
password_key = os.getenv('KEY')

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="KMLA Chatbot", page_icon="ğŸ¤–", layout="wide")

# CSSë¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬ë°± ì œê±°
st.markdown("""
    <style>
        .block-container {
            padding-top: 0rem;
        }
    </style>
    """, unsafe_allow_html=True)

st.write("ìœµí•©í”„ë¡œì íŠ¸ 2024ë…„ 1í•™ê¸° KMLA Chatbot íŒ€")
st.write(":robot_face: KMLA Chatbot - ë¯¼ì‚¬ê³ ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”!")

# ì¸ì¦ ìƒíƒœ ì´ˆê¸°í™”
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

# ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ í•„ë“œ
password = st.text_input(":name_badge: íŒ¨ìŠ¤ì›Œë“œë¥¼ ë„£ì–´ì£¼ì„¸ìš”!", type="password")

if password:
    if password == password_key:
        st.session_state.authenticated = True
        st.success("âœ… ì¸ì¦ ì„±ê³µ! ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        st.error("âŒ ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        st.session_state.authenticated = False  # ì¸ì¦ ì‹¤íŒ¨ ì‹œ ìƒíƒœ ì´ˆê¸°í™”

# ì¸ì¦ëœ ê²½ìš° ì§ˆë¬¸ ì…ë ¥ í•„ë“œ í‘œì‹œ
if st.session_state.authenticated:
    user_input = st.text_input(":eight_pointed_black_star:ë¯¼ì‚¬ê³ ì— ëŒ€í•´ ì§ˆë¬¸í•˜ê³  ì—”í„°ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”!")

    if user_input:
        # ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µ í‘œì‹œ
        st.write(':pencil2::pencil2::pencil2: ë‹µë³€ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤ :pencil2::pencil2::pencil2:')

        embeddings_model = OpenAIEmbeddings(model="text-embedding-ada-002")
        try:
            db = Chroma(persist_directory="chromadb_ada2.8", embedding_function=embeddings_model)
        except Exception as e:
            st.error(f"Error initializing database: {e}")
            raise

        # StreamHandler í´ë˜ìŠ¤ ì •ì˜
        class StreamHandler(BaseCallbackHandler):
            def __init__(self, container, initial_text=""):
                self.container = container
                self.text = initial_text

            def on_llm_new_token(self, token: str, **kwargs) -> None:
                self.text += token
                self.container.markdown(self.text)

        # Chunk ì¶”ì¶œ ë° ë¡œê·¸ ì¶œë ¥
        retriever = db.as_retriever(search_kwargs={"k": 20})  # ìƒìœ„ nê°œì˜ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰

        try:
            # ì§ˆë¬¸ì— ëŒ€í•´ ê²€ìƒ‰ëœ chunkë¥¼ ê°€ì ¸ì˜´
            relevant_docs = retriever.get_relevant_documents(user_input)
            
            #chunk_count = len(relevant_docs)  # ê²€ìƒ‰ëœ chunk ìˆ˜ ê³„ì‚°
            #st.write(f":mag: {chunk_count}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.")  # ì›¹ í™”ë©´ì— ì•Œë¦¼
            #for idx, doc in enumerate(relevant_docs):
            #    print(f"Chunk {idx + 1}: {doc.page_content}")  # VSCode í„°ë¯¸ë„ì—ë§Œ ì¶œë ¥
            #    print("================================================================================")  # êµ¬ë¶„ì„  ì¶”ê°€
        except Exception as e:
            st.error(f"Error retrieving documents: {e}")
            raise

        # LLM ë° QA ì²´ì¸ êµ¬ì„±
        chat_box = st.empty()
        stream_handler = StreamHandler(chat_box)
        llm = ChatOpenAI(model_name="gpt-4o", temperature=0.3, max_tokens=3000, streaming=True, callbacks=[stream_handler])
        qa_chain = RetrievalQA.from_chain_type(llm, retriever=db.as_retriever())

        try:
            qa_chain.invoke({"query": user_input})
        except Exception as e:
            st.error(f"Error during QA chain execution: {e}")
            raise
